{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "571c76ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b566f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.8.3-cp310-cp310-win_amd64.whl (12.2 MB)\n",
      "     ---------------------------------------- 12.2/12.2 MB 4.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (65.6.3)\n",
      "Collecting weasel<0.5.0,>=0.1.0\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "     ---------------------------------------- 50.3/50.3 kB 2.5 MB/s eta 0:00:00\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4\n",
      "  Downloading pydantic-2.10.4-py3-none-any.whl (431 kB)\n",
      "     -------------------------------------- 431.8/431.8 kB 5.4 MB/s eta 0:00:00\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.11-cp310-cp310-win_amd64.whl (25 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "     -------------------------------------- 183.0/183.0 kB 2.7 MB/s eta 0:00:00\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.10-cp310-cp310-win_amd64.whl (39 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (22.0)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.9-cp310-cp310-win_amd64.whl (122 kB)\n",
      "     -------------------------------------- 122.2/122.2 kB 3.6 MB/s eta 0:00:00\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.5.0-cp310-cp310-win_amd64.whl (632 kB)\n",
      "     -------------------------------------- 632.3/632.3 kB 4.0 MB/s eta 0:00:00\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.0\n",
      "  Downloading thinc-8.3.3-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 4.1 MB/s eta 0:00:00\n",
      "Collecting typer<1.0.0,>=0.3.0\n",
      "  Downloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "     ---------------------------------------- 44.9/44.9 kB 2.3 MB/s eta 0:00:00\n",
      "Collecting language-data>=1.2\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "     ---------------------------------------- 5.4/5.4 MB 5.6 MB/s eta 0:00:00\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting typing-extensions>=4.12.2\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Collecting pydantic-core==2.27.2\n",
      "  Downloading pydantic_core-2.27.2-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 5.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Collecting blis<1.2.0,>=1.1.0\n",
      "  Downloading blis-1.1.0-cp310-cp310-win_amd64.whl (6.4 MB)\n",
      "     ---------------------------------------- 6.4/6.4 MB 5.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.0.4)\n",
      "Collecting rich>=10.11.0\n",
      "  Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Collecting shellingham>=1.3.0\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0\n",
      "  Downloading cloudpathlib-0.20.0-py3-none-any.whl (52 kB)\n",
      "     ---------------------------------------- 52.5/52.5 kB 1.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Collecting marisa-trie>=1.1.0\n",
      "  Downloading marisa_trie-1.2.1-cp310-cp310-win_amd64.whl (151 kB)\n",
      "     -------------------------------------- 151.9/151.9 kB 9.4 MB/s eta 0:00:00\n",
      "Collecting pygments<3.0.0,>=2.13.0\n",
      "  Using cached pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: cymem, wasabi, typing-extensions, spacy-loggers, spacy-legacy, shellingham, pygments, murmurhash, mdurl, marisa-trie, catalogue, blis, annotated-types, srsly, pydantic-core, preshed, markdown-it-py, language-data, cloudpathlib, rich, pydantic, langcodes, typer, confection, weasel, thinc, spacy\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.11.2\n",
      "    Uninstalling Pygments-2.11.2:\n",
      "      Successfully uninstalled Pygments-2.11.2\n",
      "Successfully installed annotated-types-0.7.0 blis-1.1.0 catalogue-2.0.10 cloudpathlib-0.20.0 confection-0.1.5 cymem-2.0.10 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 markdown-it-py-3.0.0 mdurl-0.1.2 murmurhash-1.0.11 preshed-3.0.9 pydantic-2.10.4 pydantic-core-2.27.2 pygments-2.18.0 rich-13.9.4 shellingham-1.5.4 spacy-3.8.3 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.0 thinc-8.3.3 typer-0.15.1 typing-extensions-4.12.2 wasabi-1.1.3 weasel-0.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c158c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5be3ce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('tmdb_5000_movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a236b96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Overview:\n",
      "      budget                                             genres  \\\n",
      "0  237000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
      "1  300000000  [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...   \n",
      "2  245000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
      "3  250000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...   \n",
      "4  260000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
      "\n",
      "                                       homepage      id  \\\n",
      "0                   http://www.avatarmovie.com/   19995   \n",
      "1  http://disney.go.com/disneypictures/pirates/     285   \n",
      "2   http://www.sonypictures.com/movies/spectre/  206647   \n",
      "3            http://www.thedarkknightrises.com/   49026   \n",
      "4          http://movies.disney.com/john-carter   49529   \n",
      "\n",
      "                                            keywords original_language  \\\n",
      "0  [{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...                en   \n",
      "1  [{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...                en   \n",
      "2  [{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...                en   \n",
      "3  [{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 853,...                en   \n",
      "4  [{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...                en   \n",
      "\n",
      "                             original_title  \\\n",
      "0                                    Avatar   \n",
      "1  Pirates of the Caribbean: At World's End   \n",
      "2                                   Spectre   \n",
      "3                     The Dark Knight Rises   \n",
      "4                               John Carter   \n",
      "\n",
      "                                            overview  popularity  \\\n",
      "0  In the 22nd century, a paraplegic Marine is di...  150.437577   \n",
      "1  Captain Barbossa, long believed to be dead, ha...  139.082615   \n",
      "2  A cryptic message from Bond’s past sends him o...  107.376788   \n",
      "3  Following the death of District Attorney Harve...  112.312950   \n",
      "4  John Carter is a war-weary, former military ca...   43.926995   \n",
      "\n",
      "                                production_companies  \\\n",
      "0  [{\"name\": \"Ingenious Film Partners\", \"id\": 289...   \n",
      "1  [{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...   \n",
      "2  [{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...   \n",
      "3  [{\"name\": \"Legendary Pictures\", \"id\": 923}, {\"...   \n",
      "4        [{\"name\": \"Walt Disney Pictures\", \"id\": 2}]   \n",
      "\n",
      "                                production_countries release_date     revenue  \\\n",
      "0  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2009-12-10  2787965087   \n",
      "1  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2007-05-19   961000000   \n",
      "2  [{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...   2015-10-26   880674609   \n",
      "3  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2012-07-16  1084939099   \n",
      "4  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2012-03-07   284139100   \n",
      "\n",
      "   runtime                                   spoken_languages    status  \\\n",
      "0    162.0  [{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...  Released   \n",
      "1    169.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
      "2    148.0  [{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"},...  Released   \n",
      "3    165.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
      "4    132.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
      "\n",
      "                                          tagline  \\\n",
      "0                     Enter the World of Pandora.   \n",
      "1  At the end of the world, the adventure begins.   \n",
      "2                           A Plan No One Escapes   \n",
      "3                                 The Legend Ends   \n",
      "4            Lost in our world, found in another.   \n",
      "\n",
      "                                      title  vote_average  vote_count  \n",
      "0                                    Avatar           7.2       11800  \n",
      "1  Pirates of the Caribbean: At World's End           6.9        4500  \n",
      "2                                   Spectre           6.3        4466  \n",
      "3                     The Dark Knight Rises           7.6        9106  \n",
      "4                               John Carter           6.1        2124  \n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Overview:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "782d3e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Extract genres\n",
    "def extract_genres(genre_str):\n",
    "    \"\"\"\n",
    "    Extracts the first genre from the genre string in JSON format.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        genres = ast.literal_eval(genre_str)  # Convert the string representation of a list into a Python list\n",
    "        if genres:\n",
    "            return genres[0]['name']  # Return the name of the first genre\n",
    "    except Exception as e:\n",
    "        return None\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cc6b1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['main_genre'] = data['genres'].apply(extract_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7124086",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['main_genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe285430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and preprocess the text in the 'overview' column\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans text by removing special characters, numbers, and extra spaces.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)  # Remove special characters and numbers\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = text.strip()  # Remove leading/trailing whitespaces\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ae09bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned_overview'] = data['overview'].fillna('').apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55d8e394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "spacy.cli.download('en_core_web_sm')  # Downloads the model\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c93543e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1553972540.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[13], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    python -m spacy download en_core_web_sm\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4bd2356",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7236885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Tokenizes, lemmatizes, and removes stopwords from the text.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if token.text not in stop_words and not token.is_punct]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35ec1279",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['processed_overview'] = data['cleaned_overview'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3805b89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction using TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(data['processed_overview']).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "992c0e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable (main_genre)\n",
    "y = data['main_genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d29fb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fd668c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Random Forest Classifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2d232ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd367c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         Action       0.37      0.50      0.42       151\n",
      "      Adventure       0.22      0.03      0.05        68\n",
      "      Animation       0.00      0.00      0.00        25\n",
      "         Comedy       0.38      0.48      0.42       208\n",
      "          Crime       0.00      0.00      0.00        39\n",
      "    Documentary       0.50      0.44      0.47        18\n",
      "          Drama       0.35      0.66      0.46       242\n",
      "         Family       0.00      0.00      0.00        11\n",
      "        Fantasy       0.00      0.00      0.00        23\n",
      "        History       0.00      0.00      0.00         5\n",
      "         Horror       0.60      0.15      0.24        60\n",
      "          Music       0.00      0.00      0.00         7\n",
      "        Mystery       0.00      0.00      0.00         8\n",
      "        Romance       0.00      0.00      0.00        21\n",
      "Science Fiction       0.00      0.00      0.00        19\n",
      "       TV Movie       0.00      0.00      0.00         1\n",
      "       Thriller       0.00      0.00      0.00        39\n",
      "            War       0.00      0.00      0.00         5\n",
      "        Western       0.00      0.00      0.00         5\n",
      "\n",
      "       accuracy                           0.37       955\n",
      "      macro avg       0.13      0.12      0.11       955\n",
      "   weighted avg       0.29      0.37      0.30       955\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e422d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.36858638743455496\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ade07bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
